{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best performance with PySpark\n",
    "\n",
    "![Holden Karau](http://www.spark.tc/content/images/2016/06/Holden-Karau_sized.jpg)\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=V6DkTVvy9vk <br>\n",
    "\n",
    "https://www.youtube.com/watch?v=vfiJQ7wg81Y <br>\n",
    "\n",
    "\n",
    "https://robertovitillo.com/2015/06/30/spark-best-practices/ <br>\n",
    "https://www.slideshare.net/SparkSummit/getting-the-best-performance-with-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distrubuted Spark](http://www.bogotobogo.com/Hadoop/images/PySpark/ComponentsForDistributedExecutionInSpark.png)\n",
    "\n",
    "![PySpark Python](https://www.packtpub.com/graphics/9781786463708/graphics/B05793_03_01.jpg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count Example\n",
    "<br>\n",
    "\n",
    "<font color=  2e5f54 size=4 face=\"verdana\">Sparkâ€™s simplicity makes it all too easy to ignore its execution model and still manage to write jobs that eventually complete. With larger datasets having an understanding of what happens under the hood becomes critical to reduce run-time and avoid out of memory errors</font>\n",
    "\n",
    "### RDD operations are compiled into a Direct Acyclic Graph of RDD objects, where each RDD points to the parent it depends on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Direct Acyclic Graph of RDD objects](https://ravitillo.files.wordpress.com/2015/06/dag1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "\n",
    "### Spark UI\n",
    "\n",
    "<font color=red size=4 face=\"verdana\">Running Spark jobs without the **Spark UI** is like flying blind. The UI allows to monitor and inspect the execution of jobs. To access it remotely a SOCKS proxy is needed as the UI connects also to the worker nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try: Word Count Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Prepare for using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=C70039>First: Download some text dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "#file_url = 'http://www.gutenberg.org/cache/epub/2000/pg2000.txt'\n",
    "#file_name = '/resources/data/MSTC/cervantes.txt'\n",
    "\n",
    "#file_url = 'https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n",
    "#file_name = '/resources/data/MSTC/t8.shakespeare.txt'\n",
    "\n",
    "# NOTE that compressed files can be read as simple txt : NOTHING particular must be done!\n",
    "file_url='http://ftp.sunet.se/mirror/archive/ftp.sunet.se/pub/tv+movies/imdb/producers.list.gz'\n",
    "file_name = '/resources/data/MSTC/producers.list.gz'\n",
    "    \n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(file_url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= red>...time to measure performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color= 187b1a>Word count using RDD: reduceByKey? groupByKey?</font>\n",
    "### without ordering the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_words = sc.textFile(file_name)\n",
    "\n",
    "rdd_words = rdd_words.flatMap(lambda line: line.split()) \n",
    "\n",
    "rdd_words.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_words.takeSample(False,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "rdd_word_count = rdd_words.map(lambda word: (word, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .collect()\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_word_count[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=  #7b1864 >Word count using DataFrames:</font>\n",
    "### without ordering the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and cache a Dataframe with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.text(file_name)\n",
    "\n",
    "words=df.flatMap(lambda line: line.value.split())\\\n",
    "    .map(lambda x:Row(word=x, cnt=1)).toDF()\n",
    "    \n",
    "words.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "word_count=words.groupBy('word').count()\\\n",
    "    .collect()\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color= 187b1a>Word count using RDD</font>\n",
    "### NOW ordering the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "\n",
    "rdd_word_count = rdd_words.map(lambda word: (word,1))\\\n",
    "    .reduceByKey(lambda x,y: x + y)\\\n",
    "    .map(lambda x: (x[1],x[0])) \\\n",
    "    .sortByKey(ascending=False) \\\n",
    "    .collect()\n",
    "    \n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_word_count[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=  #7b1864 >Word count using DataFrames:</font>\n",
    "### Now ordering the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "word_count=words.groupBy('word').count()\\\n",
    "    .orderBy('count',ascending=False).collect()\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
