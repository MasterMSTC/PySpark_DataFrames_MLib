{"cells":[{"cell_type":"markdown","source":["# Let's try to understand Spark a little bit using PySpark<br> and the classical *Word Count* example\n\n# Some references:\n\n## [Holden Karau](http://www.bigdataspain.org/2017/speakers/holden-karau/)\n\n- http://youtu.be/Wg2boMqLjCg \n- https://www.youtube.com/watch?v=4xsBQYdHgn8\n- https://www.youtube.com/watch?v=V6DkTVvy9vk\n- https://www.youtube.com/watch?v=vfiJQ7wg81Y\n- https://robertovitillo.com/2015/06/30/spark-best-practices/ <br>\n- https://www.slideshare.net/SparkSummit/getting-the-best-performance-with-pyspark\n\n#### [HandySpark: bringing pandas-like capabilities to Spark DataFrames](https://towardsdatascience.com/handyspark-bringing-pandas-like-capabilities-to-spark-dataframes-5f1bcea9039e)"],"metadata":{}},{"cell_type":"markdown","source":["![Distrubuted Spark](http://www.bogotobogo.com/Hadoop/images/PySpark/ComponentsForDistributedExecutionInSpark.png)\n\n![PySpark Python](https://www.packtpub.com/graphics/9781786463708/graphics/B05793_03_01.jpg )"],"metadata":{}},{"cell_type":"markdown","source":["## Word Count Example\n- ### <font color=  2e5f54 size=6 face=\"verdana\">Sparkâ€™s simplicity makes it all too easy to ignore its execution model and still manage to write jobs that eventually complete.\n- ### With larger datasets having an understanding of what happens under the hood becomes critical to reduce run-time and avoid out of memory errors</font>\n\n### RDD operations are compiled into a Direct Acyclic Graph of RDD objects, where each RDD points to the parent it depends on:"],"metadata":{}},{"cell_type":"markdown","source":["![DAG](https://raw.githubusercontent.com/MasterMSTC/PySpark_DataFrames_MLib/master/images/image1.jpg)"],"metadata":{}},{"cell_type":"markdown","source":["![Direct Acyclic Graph of RDD objects](https://ravitillo.files.wordpress.com/2015/06/dag1.png)"],"metadata":{}},{"cell_type":"markdown","source":["## Best practices\n\n## Spark UI\n\n- ###<font color=red size=4 face=\"verdana\">Running Spark jobs without the **Spark UI** is like flying blind.\n- ### The UI allows to monitor and inspect the execution of jobs.\n- ### To access it remotely a SOCKS proxy is needed as the UI connects also to the worker nodes."],"metadata":{}},{"cell_type":"markdown","source":["## Let's try: Word Count Example"],"metadata":{}},{"cell_type":"markdown","source":["## <font color= 187b1a>Word count using RDD: reduceByKey? groupByKey?</font>"],"metadata":{}},{"cell_type":"code","source":["%sh ls /dbfs/databricks-datasets"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%sh cat /dbfs/databricks-datasets/README.md"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## <font color= 187b1a>Word count using RDD: reduceByKey</font>"],"metadata":{}},{"cell_type":"markdown","source":["- ## TO DO: cread rdd_lines from a text file `file:/dbfs/databricks-datasets/README.md `"],"metadata":{}},{"cell_type":"code","source":["rdd_lines = ???"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["rdd_lines.take(5)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["- ## TO DO: count how how many times each line of text occurs"],"metadata":{}},{"cell_type":"code","source":["???"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["- ## TO DO: to count how how many WORDS  ... we need an rdd_words !!! (splited by words!)"],"metadata":{}},{"cell_type":"code","source":["rdd_words = ???"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["rdd_words.take(5)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["- ## TO DO (Group 1): Word count using RDD: reduceByKey"],"metadata":{}},{"cell_type":"code","source":["???"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["## <font color= 187b1a>Word count using RDD: groupByKey</font>"],"metadata":{}},{"cell_type":"code","source":["???"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["## <font color=C70039>We can download some larger text files</font>"],"metadata":{}},{"cell_type":"code","source":["#import time\nimport os\n\nfrom six.moves import urllib\n\n#file_url = 'http://www.gutenberg.org/cache/epub/2000/pg2000.txt'\n#file_name = '/resources/data/MSTC/cervantes.txt'\n\n#file_url = 'https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n#file_name = '/resources/data/MSTC/t8.shakespeare.txt'\n\n# NOTE that compressed files can be read as simple txt : NOTHING particular must be done!\nfile_url='http://ftp.sunet.se/mirror/archive/ftp.sunet.se/pub/tv+movies/imdb/producers.list.gz'\nfile_name = 'producers.list.gz'\n    \nif not os.path.exists(file_name):\n    urllib.request.urlretrieve(file_url, file_name)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":25},{"cell_type":"code","source":["%sh\ngunzip producers.list.gz\nls -al"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["## <font color=  #7b1864 >Word count using DataFrames:</font>\n### without ordering the results..."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import Row\nimport pyspark.sql.functions as f\n\neDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n\neDF.select(f.explode(eDF.intlist).alias(\"LL\")).show()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["import pyspark\nimport pyspark.sql.functions as f\n\n#df = sqlContext.read.text(\"file:/databricks/driver/producers.list\")\ndf = sqlContext.read.text(\"file:/dbfs/databricks-datasets/README.md\")"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["???"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["## <font color= 187b1a>Word count using RDD</font>\n### TO DO: NOW ordering the results..."],"metadata":{}},{"cell_type":"code","source":["???"],"metadata":{"collapsed":false},"outputs":[],"execution_count":34},{"cell_type":"code","source":["rdd_word_count[0:5]"],"metadata":{"collapsed":false},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["## <font color=  #7b1864 >Word count using DataFrames:</font>\n### TO DO: Now ordering the results..."],"metadata":{}},{"cell_type":"code","source":["???"],"metadata":{"collapsed":false},"outputs":[],"execution_count":37},{"cell_type":"code","source":["word_count[0:5]"],"metadata":{"collapsed":false},"outputs":[],"execution_count":38},{"cell_type":"code","source":["\n    "],"metadata":{"collapsed":false},"outputs":[],"execution_count":39},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":40}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"WORKING_MSTC_PySpark_WordCount","notebookId":2709831939590413,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":0}
