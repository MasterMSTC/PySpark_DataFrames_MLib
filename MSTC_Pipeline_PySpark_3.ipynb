{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=  #FF5733> Now we will add more features / transformers to the PIPELINE than those in<br>\n",
    "## <font color=  #FA5733> MSTC_Pipeline_PySpark_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Churn Data\n",
    "\n",
    "###  Load churn-bigml-80.csv into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Add cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "CV_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-80.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true').cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark: ML Pipelines\n",
    "https://spark.apache.org/docs/2.2.0/ml-pipeline.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer A: StringIndexer\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>StringIndexer converts String values that are part of a look-up into categorical indices, which could be used by machine learning algorithms in ml library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer B: VectorAssembler\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>...after “feature engineering” … the feature engineering results are then combined using the VectorAssembler, before being passed to ML Estimator\n",
    "\n",
    "***Notice we provide the input = list of columns (MUST BE NUMERIC!) and the output column assembles all of them in a single column/vector***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### <font color= #C70039 > list with predictors to Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors=('Number vmail messages',\n",
    " 'Total day minutes',\n",
    " 'Total day calls',\n",
    " 'Total eve minutes',\n",
    " 'Total eve calls',\n",
    " 'Total night minutes',\n",
    " 'Total night calls',\n",
    " 'Total intl minutes',\n",
    " 'Total intl calls',\n",
    " 'Customer service calls',\n",
    " 'IntlPlan',\n",
    " 'VmailPlan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=#FF5733> Estimators\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>\n",
    "An Estimator abstracts the concept of a learning algorithm or any algorithm that fits or trains on data. \n",
    "\n",
    "Technically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. <br><br>\n",
    "***For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Index labels, adding metadata to the label column\n",
    "stringindexer = StringIndexer(inputCol='Churn',\n",
    "                             outputCol='indexedLabel')\n",
    "\n",
    "stringindexerIntlPlan = StringIndexer(inputCol='International plan',\n",
    "                             outputCol='IntlPlan')\n",
    "\n",
    "stringindexerVmailPlan = StringIndexer(inputCol='Voice mail plan',\n",
    "                             outputCol='VmailPlan')\n",
    "\n",
    "assembler=VectorAssembler(inputCols=predictors,outputCol='features')\n",
    "\n",
    "# Train a DecisionTree model\n",
    "dTree_algorithm = DecisionTreeClassifier(maxDepth=2,\n",
    "                                        labelCol='indexedLabel', featuresCol='features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain indexers and tree in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[stringindexer,\\\n",
    "                            stringindexerIntlPlan,\\\n",
    "                            stringindexerVmailPlan,\\\n",
    "                            assembler, dTree_algorithm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#938882>Model Evaluation using:\n",
    "\n",
    "* Hyperparameters seection\n",
    "* Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "evaluator=BinaryClassificationEvaluator(labelCol='indexedLabel',\\\n",
    "                                        rawPredictionCol='rawPrediction',\\\n",
    "                                       metricName='areaUnderROC')\n",
    "\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid = ParamGridBuilder().addGrid(dTree_algorithm.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed in 10.225 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "CrossvalModel=crossval.fit(CV_data)\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"calibri\" color=#d63de2> Evaluate TEST DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer : Making predictions with the TRAINED model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Evaluation on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-20.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions and evaluate result\n",
    "predictions_Test = CrossvalModel.transform(Test_data)\n",
    "accuracy_Test=evaluator.evaluate(predictions_Test)\n",
    "\n",
    "print(accuracy_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confussion Matrix\n",
    "predictions_Test.crosstab('Churn','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions and evaluate result\n",
    "#pipelineModel=pipeline.fit(CV_data)\n",
    "#predictions_Test = pipelineModel.transform(Test_data)\n",
    "#accuracy_Test=evaluator.evaluate(predictions_Test)\n",
    "\n",
    "#print(accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Evaluation on <font color=green> TRAIN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions and evaluate result\n",
    "predictions_Train = CrossvalModel.transform(CV_data)\n",
    "\n",
    "accuracy_Train=evaluator.evaluate(predictions_Train)\n",
    "\n",
    "print(accuracy_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confussion Matrix\n",
    "predictions_Train.crosstab('Churn','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipelineModel=pipeline.fit(CV_data)\n",
    "#predictions_Train = pipelineModel.transform(CV_data)\n",
    "#accuracy_Train=evaluator.evaluate(predictions_Train)\n",
    "\n",
    "#print(accuracy_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #9e9b9e >..... ANALYZE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch best model BUT TO BE USED we need process everything NO Pipes!! see below...\n",
    "Best_tree_model = Cross_res.bestModel\n",
    "print(Best_tree_model.stages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Best_tree_model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Cross_res.bestModel.stages[2]._call_java(\"toDebugString\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
