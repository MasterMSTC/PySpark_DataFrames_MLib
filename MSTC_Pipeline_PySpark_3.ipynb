{"cells":[{"cell_type":"markdown","source":["# <font color=  #FF5733> Now we will add more features / transformers to the PIPELINE than those in<br>\n## <font color=  #FA5733> MSTC_Pipeline_PySpark_2.ipynb"],"metadata":{}},{"cell_type":"markdown","source":["## Importing Churn Data\n\n###  Load churn-bigml-80.csv into a DataFrame"],"metadata":{}},{"cell_type":"markdown","source":["# <font color=red>Add cache()"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\nCV_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-80.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true').cache()\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["## Spark: ML Pipelines\nhttps://spark.apache.org/docs/2.2.0/ml-pipeline.html"],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer A: StringIndexer\n\n<font font-family: \"calibri\" size=3.5>StringIndexer converts String values that are part of a look-up into categorical indices, which could be used by machine learning algorithms in ml library."],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer B: VectorAssembler\n\n<font font-family: \"calibri\" size=3.5>...after “feature engineering” … the feature engineering results are then combined using the VectorAssembler, before being passed to ML Estimator\n\n***Notice we provide the input = list of columns (MUST BE NUMERIC!) and the output column assembles all of them in a single column/vector***"],"metadata":{}},{"cell_type":"markdown","source":["### <font color= #C70039 > list with predictors to Assemble"],"metadata":{"collapsed":false}},{"cell_type":"code","source":["predictors=('Number vmail messages',\n 'Total day minutes',\n 'Total day calls',\n 'Total eve minutes',\n 'Total eve calls',\n 'Total night minutes',\n 'Total night calls',\n 'Total intl minutes',\n 'Total intl calls',\n 'Customer service calls',\n 'IntlPlan',\n 'VmailPlan')"],"metadata":{"collapsed":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["##  <font color=#FF5733> Estimators\n\n<font font-family: \"calibri\" size=3.5>\nAn Estimator abstracts the concept of a learning algorithm or any algorithm that fits or trains on data. \n\nTechnically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. <br><br>\n***For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.***"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\n# Index labels, adding metadata to the label column\nstringindexer = StringIndexer(inputCol='Churn',\n                             outputCol='indexedLabel')\n\nstringindexerIntlPlan = StringIndexer(inputCol='International plan',\n                             outputCol='IntlPlan')\n\nstringindexerVmailPlan = StringIndexer(inputCol='Voice mail plan',\n                             outputCol='VmailPlan')\n\nassembler=VectorAssembler(inputCols=predictors,outputCol='features')\n\n# Train a DecisionTree model\ndTree_algorithm = DecisionTreeClassifier(maxDepth=2,\n                                        labelCol='indexedLabel', featuresCol='features')\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["# Chain indexers and tree in a Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[stringindexer,\\\n                            stringindexerIntlPlan,\\\n                            stringindexerVmailPlan,\\\n                            assembler, dTree_algorithm])"],"metadata":{"collapsed":false},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## <font color=#938882>Model Evaluation using:\n\n* Hyperparameters seection\n* Cross-validation"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nevaluator=BinaryClassificationEvaluator(labelCol='indexedLabel',\\\n                                        rawPredictionCol='rawPrediction',\\\n                                       metricName='areaUnderROC')\n\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(dTree_algorithm.maxDepth, [2,3,4,5,6,7]).build()\n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=3)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from time import time\n\nt0 = time()\n\nCrossvalModel=crossval.fit(CV_data)\n\ntt = time() - t0\nprint(\"Task completed in {} seconds\".format(round(tt,3)))\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["# <font face=\"calibri\" color=#d63de2> Evaluate TEST DATA"],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer : Making predictions with the TRAINED model"],"metadata":{}},{"cell_type":"markdown","source":["### <font color=red>Evaluation on TEST data"],"metadata":{}},{"cell_type":"code","source":["Test_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-20.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')"],"metadata":{"collapsed":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# make predictions and evaluate result\npredictions_Test = CrossvalModel.transform(Test_data)\naccuracy_Test=evaluator.evaluate(predictions_Test)\n\nprint(accuracy_Test)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# Confussion Matrix\npredictions_Test.crosstab('Churn','prediction').show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# make predictions and evaluate result\n#pipelineModel=pipeline.fit(CV_data)\n#predictions_Test = pipelineModel.transform(Test_data)\n#accuracy_Test=evaluator.evaluate(predictions_Test)\n\n#print(accuracy_Test)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### <font color=red>Evaluation on <font color=green> TRAIN data"],"metadata":{}},{"cell_type":"code","source":["# make predictions and evaluate result\npredictions_Train = CrossvalModel.transform(CV_data)\n\naccuracy_Train=evaluator.evaluate(predictions_Train)\n\nprint(accuracy_Train)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Confussion Matrix\npredictions_Train.crosstab('Churn','prediction').show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#pipelineModel=pipeline.fit(CV_data)\n#predictions_Train = pipelineModel.transform(CV_data)\n#accuracy_Train=evaluator.evaluate(predictions_Train)\n\n#print(accuracy_Train)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["# <font color= #9e9b9e >..... ANALYZE BEST MODEL"],"metadata":{}},{"cell_type":"code","source":["# Fetch best model BUT TO BE USED we need process everything NO Pipes!! see below...\nBest_tree_model = Cross_res.bestModel\nprint(Best_tree_model.stages[2])"],"metadata":{"collapsed":false},"outputs":[],"execution_count":29},{"cell_type":"code","source":["Best_tree_model.stages[2]"],"metadata":{"collapsed":false},"outputs":[],"execution_count":30},{"cell_type":"code","source":["print(Cross_res.bestModel.stages[2]._call_java(\"toDebugString\"))"],"metadata":{"collapsed":false},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":33}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"MSTC_Pipeline_PySpark_3","notebookId":2515846536832129,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":0}
