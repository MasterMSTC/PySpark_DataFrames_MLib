{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=  #FF5733> Now we will add more features / transformers to the PIPELINE than those in<br>\n",
    "## <font color=  #FA5733> MSTC_Pipeline_PySpark_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Churn Data\n",
    "\n",
    "###  Load churn-bigml-80.csv into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Add cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "CV_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-80.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true').cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark: ML Pipelines\n",
    "https://spark.apache.org/docs/2.2.0/ml-pipeline.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer A: StringIndexer\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>StringIndexer converts String values that are part of a look-up into categorical indices, which could be used by machine learning algorithms in ml library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer B: VectorAssembler\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>...after “feature engineering” … the feature engineering results are then combined using the VectorAssembler, before being passed to ML Estimator\n",
    "\n",
    "***Notice we provide the input = list of columns (MUST BE NUMERIC!) and the output column assembles all of them in a single column/vector***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### <font color= #C70039 > list with predictors to Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors=('Number vmail messages',\n",
    " 'Total day minutes',\n",
    " 'Total day calls',\n",
    " 'Total eve minutes',\n",
    " 'Total eve calls',\n",
    " 'Total night minutes',\n",
    " 'Total night calls',\n",
    " 'Total intl minutes',\n",
    " 'Total intl calls',\n",
    " 'Customer service calls',\n",
    " 'IntlPlan',\n",
    " 'VmailPlan',\n",
    " 'StateOHE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=#FF5733> Estimators\n",
    "\n",
    "<font font-family: \"calibri\" size=3.5>\n",
    "An Estimator abstracts the concept of a learning algorithm or any algorithm that fits or trains on data. \n",
    "\n",
    "Technically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. <br><br>\n",
    "***For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Index labels, adding metadata to the label column\n",
    "stringindexer = StringIndexer(inputCol='Churn',\n",
    "                             outputCol='indexedLabel')\n",
    "\n",
    "stringindexerIntlPlan = StringIndexer(inputCol='International plan',\n",
    "                             outputCol='IntlPlan')\n",
    "\n",
    "stringindexerVmailPlan = StringIndexer(inputCol='Voice mail plan',\n",
    "                             outputCol='VmailPlan')\n",
    "\n",
    "# ADD CATEGORICAL USING OHE:\n",
    "##### First: need Indexer\n",
    "stringindexerStateNum = StringIndexer(inputCol='State',\n",
    "                             outputCol='StateNum')\n",
    "##### Then: we can apply OHE on StateNum\n",
    "\n",
    "## NOTE WE HAVE TO ADD:\n",
    "# from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "OHEencoderState=OneHotEncoder(dropLast=False, inputCol='StateNum',\n",
    "                             outputCol='StateOHE')\n",
    "\n",
    "#### SEE DENSE , SPARSE VECTORS... and Assembled vector\n",
    "\n",
    "assembler=VectorAssembler(inputCols=predictors,outputCol='features')\n",
    "\n",
    "# Train a DecisionTree model\n",
    "dTree_algorithm = DecisionTreeClassifier(maxDepth=2,\n",
    "                                        labelCol='indexedLabel', featuresCol='features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain indexers and tree in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[stringindexer,\\\n",
    "                            stringindexerIntlPlan,\\\n",
    "                            stringindexerVmailPlan,\\\n",
    "                            stringindexerStateNum,\\\n",
    "                            OHEencoderState,\\\n",
    "                            assembler, dTree_algorithm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#938882>Model Evaluation using:\n",
    "\n",
    "* Hyperparameters seection\n",
    "* Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "evaluator=BinaryClassificationEvaluator(labelCol='indexedLabel',\\\n",
    "                                        rawPredictionCol='rawPrediction',\\\n",
    "                                       metricName='areaUnderROC')\n",
    "\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid = ParamGridBuilder().addGrid(dTree_algorithm.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed in 24.781 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "CrossvalModel=crossval.fit(CV_data)\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"Task completed in {} seconds\".format(round(tt,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=magenta> Let's see the OHE implications ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringindexerStateNum = StringIndexer(inputCol='State',\n",
    "                             outputCol='StateNum')\n",
    "\n",
    "model1=stringindexerStateNum.fit(CV_data)\n",
    "\n",
    "TransformState_Num=model1.transform(CV_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>StateNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  StateNum\n",
       "0    KS      23.0\n",
       "1    OH       4.0\n",
       "2    NJ      27.0\n",
       "3    OH       4.0\n",
       "4    OK      24.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(TransformState_Num.select('State','StateNum').take(5), columns=('State','StateNum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OHEencoderState=OneHotEncoder(dropLast=False, inputCol='StateNum',\n",
    "                             outputCol='StateOHE')\n",
    "\n",
    "TransformState_OHE=OHEencoderState.transform(TransformState_Num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color= #6fb92d >NOTE : <font color=red>SparseVector</font> format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(State='KS', StateNum=23.0, StateOHE=SparseVector(51, {23: 1.0})),\n",
       " Row(State='OH', StateNum=4.0, StateOHE=SparseVector(51, {4: 1.0})),\n",
       " Row(State='NJ', StateNum=27.0, StateOHE=SparseVector(51, {27: 1.0})),\n",
       " Row(State='OH', StateNum=4.0, StateOHE=SparseVector(51, {4: 1.0})),\n",
       " Row(State='OK', StateNum=24.0, StateOHE=SparseVector(51, {24: 1.0}))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformState_OHE.select('State','StateNum','StateOHE')\\\n",
    "             .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=('Total day calls','Total eve minutes','StateOHE'),\\\n",
    "                          outputCol='features')\n",
    "\n",
    "VectorAssembled=assembler.transform(TransformState_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(53, {0: 110.0, 1: 197.4, 25: 1.0})),\n",
       " Row(features=SparseVector(53, {0: 123.0, 1: 195.5, 6: 1.0})),\n",
       " Row(features=SparseVector(53, {0: 114.0, 1: 121.2, 29: 1.0})),\n",
       " Row(features=SparseVector(53, {0: 71.0, 1: 61.9, 6: 1.0})),\n",
       " Row(features=SparseVector(53, {0: 113.0, 1: 148.3, 26: 1.0}))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VectorAssembled.select('features').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"calibri\" color=#d63de2> Evaluate TEST DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color= #e38009> Transformer : Making predictions with the TRAINED model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Evaluation on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_data = sqlContext.read.load('/resources/data/MSTC/churn-bigml-20.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7291958041958042\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate result\n",
    "predictions_Test = CrossvalModel.transform(Test_data)\n",
    "accuracy_Test=evaluator.evaluate(predictions_Test)\n",
    "\n",
    "print(accuracy_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|Churn_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|            True| 24| 71|\n",
      "|           False|556| 16|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confussion Matrix\n",
    "predictions_Test.crosstab('Churn','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions and evaluate result\n",
    "#pipelineModel=pipeline.fit(CV_data)\n",
    "#predictions_Test = pipelineModel.transform(Test_data)\n",
    "#accuracy_Test=evaluator.evaluate(predictions_Test)\n",
    "\n",
    "#print(accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Evaluation on <font color=green> TRAIN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7764757926558837\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate result\n",
    "predictions_Train = CrossvalModel.transform(CV_data)\n",
    "\n",
    "accuracy_Train=evaluator.evaluate(predictions_Train)\n",
    "\n",
    "print(accuracy_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+---+\n",
      "|Churn_prediction| 0.0|1.0|\n",
      "+----------------+----+---+\n",
      "|            True|  66|322|\n",
      "|           False|2264| 14|\n",
      "+----------------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confussion Matrix\n",
    "predictions_Train.crosstab('Churn','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#pipelineModel=pipeline.fit(CV_data)\n",
    "#predictions_Train = pipelineModel.transform(CV_data)\n",
    "#accuracy_Train=evaluator.evaluate(predictions_Train)\n",
    "\n",
    "#print(accuracy_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= #9e9b9e >..... ANALYZE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch best model BUT TO BE USED we need process everything NO Pipes!! see below...\n",
    "Best_tree_model = Cross_res.bestModel\n",
    "print(Best_tree_model.stages[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Best_tree_model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Cross_res.bestModel.stages[2]._call_java(\"toDebugString\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
