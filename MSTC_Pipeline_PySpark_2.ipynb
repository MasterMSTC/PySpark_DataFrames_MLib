{"cells":[{"cell_type":"code","source":["displayHTML(\"<font size=8 color=black> Let's start building a PIPELINE using the elements in<br> <font color=  #FA5733> MSTC_Pipeline_PySpark_1.ipynb\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<font size=8 color=black> Let's start building a PIPELINE using the elements in<br> <font color=  #FA5733> MSTC_Pipeline_PySpark_1.ipynb"]}}],"execution_count":1},{"cell_type":"markdown","source":["### [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT:"],"metadata":{}},{"cell_type":"markdown","source":["## Importing Churn Data\n\n###  Load churn-bigml-80.csv into a DataFrame"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\nCV_data = sqlContext.read.load('/FileStore/tables/churn_bigml_80-bf1a8.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\nfrom pyspark.sql.types import DoubleType, StringType\nfrom pyspark.sql.functions import UserDefinedFunction\n\ntoStr = UserDefinedFunction(lambda k: k, StringType())\nCV_data = CV_data.withColumn('Churn', toStr(CV_data['Churn']))\n"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Spark: ML Pipelines\nhttps://spark.apache.org/docs/2.2.0/ml-pipeline.html"],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer A: StringIndexer\n\n<font font-family: \"calibri\" size=3.5>StringIndexer converts String values that are part of a look-up into categorical indices, which could be used by machine learning algorithms in ml library."],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer B: VectorAssembler\n\n<font font-family: \"calibri\" size=3.5>...after “feature engineering” … the feature engineering results are then combined using the VectorAssembler, before being passed to ML Estimator\n\n***Notice we provide the input = list of columns (MUST BE NUMERIC!) and the output column assembles all of them in a single column/vector***"],"metadata":{}},{"cell_type":"markdown","source":["### <font color= #C70039 > list with predictors to Assemble"],"metadata":{"collapsed":false}},{"cell_type":"code","source":["predictors=('Number vmail messages',\n 'Total day minutes',\n 'Total day calls',\n 'Total eve minutes',\n 'Total eve calls',\n 'Total night minutes',\n 'Total night calls',\n 'Total intl minutes',\n 'Total intl calls',\n 'Customer service calls')"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["##  <font color=#FF5733> Estimators\n\n<font font-family: \"calibri\" size=3.5>\nAn Estimator abstracts the concept of a learning algorithm or any algorithm that fits or trains on data. \n\nTechnically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. <br><br>\n***For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.***"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\n# Index labels, adding metadata to the label column\nstringindexer = StringIndexer(inputCol='Churn',\n                             outputCol='indexedLabel')\n\nassembler=VectorAssembler(inputCols=predictors,outputCol='features')\n\n# Train a DecisionTree model\ndTree_algorithm = DecisionTreeClassifier(maxDepth=2,\n                                        labelCol='indexedLabel', featuresCol='features')\n"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["# Chain indexers and tree in a Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[stringindexer,\\\n                            assembler, dTree_algorithm])"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["## <font color=#938882>Model Evaluation using:\n\n* Hyperparameters selection\n* Cross-validation"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nevaluator=BinaryClassificationEvaluator(labelCol='indexedLabel',\\\n                                        rawPredictionCol='rawPrediction',\\\n                                       metricName='areaUnderROC')\n\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(dTree_algorithm.maxDepth, [2,3,4,5,6,7]).build()\n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=3)"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["CrossvalModel=crossval.fit(CV_data)"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["# <font face=\"calibri\" color=#d63de2> Evaluate TEST DATA"],"metadata":{}},{"cell_type":"markdown","source":["##  <font color= #e38009> Transformer : Making predictions with the TRAINED model"],"metadata":{}},{"cell_type":"markdown","source":["### <font color=red>Evaluation on TEST data"],"metadata":{}},{"cell_type":"code","source":["%sh ls /dbfs/FileStore/tables"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">churn_bigml_20-55239.csv\nchurn_bigml_80-bf1a8.csv\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["Test_data = sqlContext.read.load('/FileStore/tables/churn_bigml_20-55239.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\nfrom pyspark.sql.types import DoubleType, StringType\nfrom pyspark.sql.functions import UserDefinedFunction\n\ntoStr = UserDefinedFunction(lambda k: k, StringType())\nTest_data = Test_data.withColumn('Churn', toStr(Test_data['Churn']))"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["# make predictions and evaluate result\npredictions_Test = CrossvalModel.transform(Test_data)\naccuracy_Test=evaluator.evaluate(predictions_Test)\n\nprint(accuracy_Test)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# make predictions and evaluate result\n#pipelineModel=pipeline.fit(CV_data)\n#predictions_Test = pipelineModel.transform(Test_data)\n#accuracy_Test=evaluator.evaluate(predictions_Test)\n\n#print(accuracy_Test)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### <font color=red>Evaluation on <font color=green> TRAIN data"],"metadata":{}},{"cell_type":"code","source":["# make predictions and evaluate result\npredictions_Train = CrossvalModel.transform(CV_data)\n\naccuracy_Train=evaluator.evaluate(predictions_Train)\n\nprint(accuracy_Train)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#pipelineModel=pipeline.fit(CV_data)\n#predictions_Train = pipelineModel.transform(CV_data)\n#accuracy_Train=evaluator.evaluate(predictions_Train)\n\n#print(accuracy_Train)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["# <font color= #9e9b9e >..... ANALYZE BEST MODEL"],"metadata":{}},{"cell_type":"code","source":["# Fetch best model BUT TO BE USED we need process everything NO Pipes!! see below...\nBest_tree_model = CrossvalModel.bestModel\nprint(Best_tree_model.stages[2])"],"metadata":{"collapsed":false},"outputs":[],"execution_count":28},{"cell_type":"code","source":["print(Best_tree_model.stages[2]._call_java(\"toDebugString\"))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":29}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"MSTC_Pipeline_PySpark_2","notebookId":2515846536832095,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":0}
